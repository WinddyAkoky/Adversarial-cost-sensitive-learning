{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from torch import nn\n",
    "import copy\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd.gradcheck import zero_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet 网络\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "def my_fgsm(input, labels, model, criterion, epsilon, device, c=None):\n",
    "    assert isinstance(model, torch.nn.Module), \"Input parameter model is not nn.Module. Check the model\"\n",
    "    assert isinstance(criterion, torch.nn.Module), \"Input parameter criterion is no Loss. Check the criterion\"\n",
    "    assert (0 <= epsilon <= 1), \"episilon must be 0 <= epsilon <= 1\"\n",
    "\n",
    "    # For calculating gradient\n",
    "    input_for_gradient = Variable(input, requires_grad=True).to(device)\n",
    "    out = model(input_for_gradient)\n",
    "    if c==None:\n",
    "        loss = criterion(out, Variable(labels))\n",
    "    else:\n",
    "        loss = criterion(out, Variable(labels), c)\n",
    "\n",
    "    # Calculate gradient\n",
    "    loss.backward()\n",
    "\n",
    "    # Calculate sign of gradient\n",
    "    signs = torch.sign(input_for_gradient.grad.data)\n",
    "\n",
    "    # Add\n",
    "    input_for_gradient.data = input_for_gradient.data + (epsilon * signs)\n",
    "\n",
    "    return input_for_gradient, signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练LeNet\n",
    "\n",
    "记作：model_NORMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE = True\n",
    "if NORMALIZE:\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "else:\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = 'F:\\\\work'\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(root=os.path.join(data_home, 'dataset/MNIST'), train=True, download=True, transform=trans)\n",
    "test_set = torchvision.datasets.MNIST(root=os.path.join(data_home, 'dataset/MNIST'), train=False, download=True, transform=trans)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60000|60000epoch: 0, test correct on clean data: 0.9468\n",
      " 60000|60000epoch: 1, test correct on clean data: 0.9703\n",
      " 60000|60000epoch: 2, test correct on clean data: 0.9821\n",
      " 60000|60000epoch: 3, test correct on clean data: 0.9839\n",
      " 60000|60000epoch: 4, test correct on clean data: 0.985\n",
      " 60000|60000epoch: 5, test correct on clean data: 0.9864\n",
      " 60000|60000epoch: 6, test correct on clean data: 0.9879\n",
      " 60000|60000epoch: 7, test correct on clean data: 0.9881\n",
      " 60000|60000epoch: 8, test correct on clean data: 0.9877\n",
      " 60000|60000epoch: 9, test correct on clean data: 0.9882\n"
     ]
    }
   ],
   "source": [
    "# 声明网络\n",
    "model_NORMAL = LeNet()\n",
    "model_NORMAL = model_NORMAL.to(DEVICE)\n",
    "\n",
    "# 参数\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "optimizer_NORMAL = torch.optim.SGD(params=model_NORMAL.parameters(), lr=learning_rate, momentum=0.5)\n",
    "criterion_NORMAL = torch.nn.functional.cross_entropy\n",
    "\n",
    "# 开始训练\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_NORMAL.train()\n",
    "    count = 0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "        optimizer_NORMAL.zero_grad()\n",
    "        output = model_NORMAL(data)\n",
    "        loss = criterion_NORMAL(output, target)\n",
    "        loss.backward()\n",
    "        optimizer_NORMAL.step()\n",
    "    \n",
    "        count += len(data)\n",
    "        print('\\r {}|{}'.format(count, len(train_loader.dataset)), end='')\n",
    "    \n",
    "    # 测试\n",
    "    correct = 0\n",
    "    model_NORMAL.eval()\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        output = model_NORMAL(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    print('epoch: {}, test correct on clean data: {}'.format(epoch,correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 980\n",
      " 0 correct: 0.8316326530612245\n",
      " 1135\n",
      " 1 correct: 0.8405286343612335\n",
      " 1032\n",
      " 2 correct: 0.6036821705426356\n",
      " 1010\n",
      " 3 correct: 0.8118811881188119\n",
      " 982\n",
      " 4 correct: 0.4226069246435845\n",
      " 892\n",
      " 5 correct: 0.7219730941704036\n",
      " 958\n",
      " 6 correct: 0.7807933194154488\n",
      " 1028\n",
      " 7 correct: 0.6585603112840467\n",
      " 974\n",
      " 8 correct: 0.5328542094455853\n",
      " 1009\n",
      " 9 correct: 0.6392467789890981\n",
      "avg acc on FGSM attach: 0.686\n"
     ]
    }
   ],
   "source": [
    "# model_NORMAL 的对抗（FGSM）测试\n",
    "epsilon = 0.3\n",
    "\n",
    "model_NORMAL.eval()\n",
    "correct_total = 0\n",
    "criterion_NORMAL = nn.CrossEntropyLoss()\n",
    "for special_index in range(10):\n",
    "    count = 0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data[target==special_index]\n",
    "        target = target[target==special_index]\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        data, sign = my_fgsm(data, target, model_NORMAL, criterion_NORMAL, epsilon, DEVICE)\n",
    "        output = model_NORMAL(data)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        count += len(data)\n",
    "        print('\\r {}'.format(count), end='')\n",
    "    correct_total += correct\n",
    "    print('\\n {} correct: {}'.format(special_index,correct/count))\n",
    "print('avg acc on FGSM attach: {}'.format(correct_total/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet对抗训练\n",
    "\n",
    "FGSM生成对抗样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60000|60000epoch:0, test correct: 0.9077\n",
      " 60000|60000epoch:1, test correct: 0.922\n",
      " 60000|60000epoch:2, test correct: 0.9321\n",
      " 60000|60000epoch:3, test correct: 0.9333\n",
      " 60000|60000epoch:4, test correct: 0.9358\n",
      " 60000|60000epoch:5, test correct: 0.9342\n",
      " 60000|60000epoch:6, test correct: 0.9413\n",
      " 60000|60000epoch:7, test correct: 0.9457\n",
      " 60000|60000epoch:8, test correct: 0.9471\n",
      " 60000|60000epoch:9, test correct: 0.9474\n"
     ]
    }
   ],
   "source": [
    "# 声明网络，并用model_NORMAL初始化\n",
    "model_ADV = copy.deepcopy(model_NORMAL)\n",
    "model_ADV = model_ADV.to(DEVICE)\n",
    "\n",
    "epsilon = 0.3\n",
    "criterion_ADV = torch.nn.functional.cross_entropy\n",
    "criterion_ADV_v = nn.CrossEntropyLoss()\n",
    "optimizer_ADV = torch.optim.SGD(params=model_ADV.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "for epoch in range(10):\n",
    "    count = 0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "        data, sign = my_fgsm(data, target, model_ADV, criterion_ADV_v, epsilon, DEVICE)\n",
    "\n",
    "        optimizer_ADV.zero_grad()\n",
    "        output = model_ADV(data)\n",
    "        loss = criterion_ADV(output, target)\n",
    "        loss.backward()\n",
    "        optimizer_ADV.step()\n",
    "        count += len(data)\n",
    "        print('\\r {}|{}'.format(count, len(train_loader.dataset)), end='')\n",
    "      \n",
    "    # 测试\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "        data, sign = my_fgsm(data, target, model_ADV, criterion_ADV_v, epsilon, DEVICE)\n",
    "\n",
    "        output = model_ADV(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    print('epoch:{}, test correct: {}'.format(epoch, correct/len(test_loader.dataset)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 980\n",
      " 0 correct: 0.9795918367346939\n",
      " 1135\n",
      " 1 correct: 0.9859030837004406\n",
      " 1032\n",
      " 2 correct: 0.9437984496124031\n",
      " 1010\n",
      " 3 correct: 0.9603960396039604\n",
      " 982\n",
      " 4 correct: 0.9348268839103869\n",
      " 892\n",
      " 5 correct: 0.9473094170403588\n",
      " 958\n",
      " 6 correct: 0.9582463465553236\n",
      " 1028\n",
      " 7 correct: 0.943579766536965\n",
      " 974\n",
      " 8 correct: 0.9158110882956879\n",
      " 1009\n",
      " 9 correct: 0.8999008919722498\n",
      "avg acc on FGSM attach: 0.9474\n"
     ]
    }
   ],
   "source": [
    "## 测试model_ADV每一类的在FGSM样本上的准确率\n",
    "epsilon = 0.3\n",
    "\n",
    "model_ADV.eval()\n",
    "correct_total = 0\n",
    "for special_index in range(10):\n",
    "    count = 0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data[target==special_index]\n",
    "        target = target[target==special_index]\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        data, sign = my_fgsm(data, target, model_ADV, criterion_ADV_v, epsilon, DEVICE)\n",
    "        output = model_ADV(data)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        count += len(data)\n",
    "        print('\\r {}'.format(count), end='')\n",
    "    correct_total += correct\n",
    "    print('\\n {} correct: {}'.format(special_index,correct/count))\n",
    "print('avg acc on FGSM attach: {}'.format(correct_total/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练CSE\n",
    "\n",
    "只训练保护类0的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_cost_sensitive(nn.Module):\n",
    "    def __init__(self,model):\n",
    "        super(Loss_cost_sensitive, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, data, target, c):\n",
    "        \n",
    "        l1 = F.cross_entropy(data, target, reduction='mean')\n",
    "        p = F.softmax(data, 1)\n",
    "        \n",
    "        cost_sentive = c[:,target]\n",
    "        cost_sentive = cost_sentive.T\n",
    "        l2 = p.mul(cost_sentive)\n",
    "        l2 = l2.sum(1).mean()\n",
    "        \n",
    "        conv_weight = self.model.conv1.weight\n",
    "        loss_x = torch.norm(conv_weight, p=1) - torch.norm(conv_weight, p=2)\n",
    "        \n",
    "        return l1+l2 + loss_x\n",
    "    \n",
    "def get_cost_matric(i_label):\n",
    "    C = torch.ones(10,10)\n",
    "    C[i_label,:] = 10\n",
    "    C[:,i_label] = 10\n",
    "    C = C - torch.diag(C.diag())\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60000|60000epoch: 0, test correct: 0.977\n",
      " 60000|60000epoch: 1, test correct: 0.9764\n",
      " 60000|60000epoch: 2, test correct: 0.9816\n",
      " 60000|60000epoch: 3, test correct: 0.981\n",
      " 60000|60000epoch: 4, test correct: 0.9841\n",
      " 60000|60000epoch: 5, test correct: 0.9835\n",
      " 60000|60000epoch: 6, test correct: 0.9823\n",
      " 60000|60000epoch: 7, test correct: 0.9834\n",
      " 60000|60000epoch: 8, test correct: 0.985\n",
      " 60000|60000epoch: 9, test correct: 0.9847\n"
     ]
    }
   ],
   "source": [
    "# 声明网络并初始化\n",
    "model_CSE_0 = copy.deepcopy(model_NORMAL)\n",
    "model_CSE_0 = model_CSE_0.to(DEVICE)\n",
    "\n",
    "criterion_CSE = Loss_cost_sensitive(model_CSE_0)\n",
    "optimizer_CSE = torch.optim.SGD(params=model_CSE_0.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "# 生成保护0类的代价矩阵\n",
    "C = get_cost_matric(0)\n",
    "C = C.to(DEVICE)\n",
    "\n",
    "# 开始训练\n",
    "for epoch in range(10):\n",
    "    count = 0\n",
    "    model_CSE_0.train()\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer_CSE.zero_grad()\n",
    "        output = model_CSE_0(data)\n",
    "        loss = criterion_CSE(output, target, C)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_CSE.step()\n",
    "\n",
    "        count += len(data)\n",
    "        print('\\r {}|{}'.format(count, len(train_loader.dataset)), end='')\n",
    "\n",
    "    # 测试\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        output = model_CSE_0(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    print('epoch: {}, test correct: {}'.format(epoch,correct/len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 980\n",
      " 0 correct: 0.9846938775510204\n",
      " 1135\n",
      " 1 correct: 0.9806167400881057\n",
      " 1032\n",
      " 2 correct: 0.9486434108527132\n",
      " 1010\n",
      " 3 correct: 0.9435643564356435\n",
      " 982\n",
      " 4 correct: 0.9419551934826884\n",
      " 892\n",
      " 5 correct: 0.9159192825112108\n",
      " 958\n",
      " 6 correct: 0.965553235908142\n",
      " 1028\n",
      " 7 correct: 0.9542801556420234\n",
      " 974\n",
      " 8 correct: 0.8655030800821355\n",
      " 1009\n",
      " 9 correct: 0.8572844400396432\n",
      "avg acc on FGSM attach: 0.9366\n"
     ]
    }
   ],
   "source": [
    "# 测试CSE在FGSM样本下每一类的准确率\n",
    "epsilon = 0.3\n",
    "\n",
    "model_CSE_0.eval()\n",
    "correct_total = 0\n",
    "for special_index in range(10):\n",
    "    count = 0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data[target==special_index]\n",
    "        target = target[target==special_index]\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        data, sign = my_fgsm(data, target, model_CSE_0, criterion_CSE, epsilon, DEVICE, C)\n",
    "        output = model_CSE_0(data)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        count += len(data)\n",
    "        print('\\r {}'.format(count), end='')\n",
    "    correct_total += correct\n",
    "    print('\\n {} correct: {}'.format(special_index,correct/count))\n",
    "print('avg acc on FGSM attach: {}'.format(correct_total/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试上面三个模型在deepfool下的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfool(image, net, num_classes=10, overshoot=0.02, max_iter=3):\n",
    "\n",
    "    \"\"\"\n",
    "       :param image: Image of size HxWx3\n",
    "       :param net: network (input: images, output: values of activation **BEFORE** softmax).\n",
    "       :param num_classes: num_classes (limits the number of classes to test against, by default = 10)\n",
    "       :param overshoot: used as a termination criterion to prevent vanishing updates (default = 0.02).\n",
    "       :param max_iter: maximum number of iterations for deepfool (default = 50)\n",
    "       :return: minimal perturbation that fools the classifier, number of iterations that it required, new estimated_label and perturbed image\n",
    "    \"\"\"\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "\n",
    "    if is_cuda:\n",
    "#         print(\"Using GPU\")\n",
    "        image = image.cuda()\n",
    "        net = net.cuda()\n",
    "    else:\n",
    "        pass\n",
    "#         print(\"Using CPU\")\n",
    "\n",
    "\n",
    "    f_image = net.forward(Variable(image[None, :, :, :], requires_grad=True)).data.cpu().numpy().flatten()\n",
    "    I = (np.array(f_image)).flatten().argsort()[::-1]\n",
    "\n",
    "    I = I[0:num_classes]\n",
    "    label = I[0]\n",
    "\n",
    "    input_shape = image.cpu().numpy().shape\n",
    "    pert_image = copy.deepcopy(image)\n",
    "    w = np.zeros(input_shape)\n",
    "    r_tot = np.zeros(input_shape)\n",
    "\n",
    "    loop_i = 0\n",
    "\n",
    "    x = Variable(pert_image[None, :], requires_grad=True)\n",
    "    fs = net.forward(x)\n",
    "    fs_list = [fs[0,I[k]] for k in range(num_classes)]\n",
    "    k_i = label\n",
    "\n",
    "    while k_i == label and loop_i < max_iter:\n",
    "\n",
    "        pert = np.inf\n",
    "        fs[0, I[0]].backward(retain_graph=True)\n",
    "        grad_orig = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "        for k in range(1, num_classes):\n",
    "            zero_gradients(x)\n",
    "\n",
    "            fs[0, I[k]].backward(retain_graph=True)\n",
    "            cur_grad = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "            # set new w_k and new f_k\n",
    "            w_k = cur_grad - grad_orig\n",
    "            f_k = (fs[0, I[k]] - fs[0, I[0]]).data.cpu().numpy()\n",
    "\n",
    "            pert_k = abs(f_k)/np.linalg.norm(w_k.flatten())\n",
    "\n",
    "            # determine which w_k to use\n",
    "            if pert_k < pert:\n",
    "                pert = pert_k\n",
    "                w = w_k\n",
    "\n",
    "        # compute r_i and r_tot\n",
    "        # Added 1e-4 for numerical stability\n",
    "        r_i =  (pert+1e-4) * w / np.linalg.norm(w)\n",
    "        r_tot = np.float32(r_tot + r_i)\n",
    "\n",
    "        if is_cuda:\n",
    "            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot).cuda()\n",
    "        else:\n",
    "            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot)\n",
    "\n",
    "        x = Variable(pert_image, requires_grad=True)\n",
    "        fs = net.forward(x)\n",
    "        k_i = np.argmax(fs.data.cpu().numpy().flatten())\n",
    "\n",
    "        loop_i += 1\n",
    "\n",
    "    r_tot = (1+overshoot)*r_tot\n",
    "\n",
    "    return r_tot, loop_i, label, k_i, pert_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 980\n",
      " 0 correct: 0.8683673469387755\n",
      " 1135\n",
      " 1 correct: 0.8449339207048459\n",
      " 1032\n",
      " 2 correct: 0.7868217054263565\n",
      " 1010\n",
      " 3 correct: 0.801980198019802\n",
      " 982\n",
      " 4 correct: 0.7260692464358453\n",
      " 892\n",
      " 5 correct: 0.7488789237668162\n",
      " 958\n",
      " 6 correct: 0.848643006263048\n",
      " 1028\n",
      " 7 correct: 0.7675097276264592\n",
      " 974\n",
      " 8 correct: 0.6765913757700205\n",
      " 1009\n",
      " 9 correct: 0.5153617443012884\n",
      "avg acc on FGSM attach: 0.7594\n"
     ]
    }
   ],
   "source": [
    "# 测试CSE在FGSM样本下每一类的准确率\n",
    "\n",
    "model_CSE_0.eval()\n",
    "correct_total = 0\n",
    "for special_index in range(10):\n",
    "    count = 0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data[target==special_index]\n",
    "        target = target[target==special_index]\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        data = data.reshape(1,28,28)\n",
    "        r, loop_i, label_orig, label_pert, pert_image = deepfool(data, model_CSE_0)\n",
    "        output = model_CSE_0(pert_image)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        count += len(data)\n",
    "        print('\\r {}'.format(count), end='')\n",
    "    correct_total += correct\n",
    "    print('\\n {} correct: {}'.format(special_index,correct/count))\n",
    "print('avg acc on FGSM attach: {}'.format(correct_total/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 980\n",
      " 0 correct: 0.2571428571428571\n",
      " 1135\n",
      " 1 correct: 0.3832599118942731\n",
      " 1032\n",
      " 2 correct: 0.24321705426356588\n",
      " 1010\n",
      " 3 correct: 0.3425742574257426\n",
      " 982\n",
      " 4 correct: 0.11507128309572301\n",
      " 892\n",
      " 5 correct: 0.38228699551569506\n",
      " 958\n",
      " 6 correct: 0.21085594989561587\n",
      " 1028\n",
      " 7 correct: 0.20428015564202334\n",
      " 974\n",
      " 8 correct: 0.16119096509240247\n",
      " 1009\n",
      " 9 correct: 0.09117938553022795\n",
      "avg acc on FGSM attach: 0.2399\n"
     ]
    }
   ],
   "source": [
    "model_ADV.eval()\n",
    "correct_total = 0\n",
    "for special_index in range(10):\n",
    "    count = 0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data[target==special_index]\n",
    "        target = target[target==special_index]\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        data = data.reshape(1,28,28)\n",
    "        r, loop_i, label_orig, label_pert, pert_image = deepfool(data, model_ADV)\n",
    "        output = model_ADV(pert_image)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        count += len(data)\n",
    "        print('\\r {}'.format(count), end='')\n",
    "    correct_total += correct\n",
    "    print('\\n {} correct: {}'.format(special_index,correct/count))\n",
    "print('avg acc on FGSM attach: {}'.format(correct_total/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 980\n",
      " 0 correct: 0.0336734693877551\n",
      " 1135\n",
      " 1 correct: 0.04669603524229075\n",
      " 1032\n",
      " 2 correct: 0.050387596899224806\n",
      " 1010\n",
      " 3 correct: 0.09504950495049505\n",
      " 982\n",
      " 4 correct: 0.023421588594704685\n",
      " 892\n",
      " 5 correct: 0.0795964125560538\n",
      " 958\n",
      " 6 correct: 0.04488517745302714\n",
      " 1028\n",
      " 7 correct: 0.04669260700389105\n",
      " 974\n",
      " 8 correct: 0.054414784394250515\n",
      " 1009\n",
      " 9 correct: 0.007928642220019821\n",
      "avg acc on FGSM attach: 0.048\n"
     ]
    }
   ],
   "source": [
    "model_NORMAL.eval()\n",
    "correct_total = 0\n",
    "for special_index in range(10):\n",
    "    count = 0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data[target==special_index]\n",
    "        target = target[target==special_index]\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        data = data.reshape(1,28,28)\n",
    "        r, loop_i, label_orig, label_pert, pert_image = deepfool(data, model_NORMAL)\n",
    "        output = model_NORMAL(pert_image)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        count += len(data)\n",
    "        print('\\r {}'.format(count), end='')\n",
    "    correct_total += correct\n",
    "    print('\\n {} correct: {}'.format(special_index,correct/count))\n",
    "print('avg acc on FGSM attach: {}'.format(correct_total/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
